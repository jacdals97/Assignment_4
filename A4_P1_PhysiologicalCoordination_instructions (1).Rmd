---
title: "Assignment 4 - Heart rate, respiration and interpersonal coordination"
author: "Aske Bredahl, Johan Horsmans, Jacob Dalsgaard, Stine Nyhus, Eva Hansen"
date: "December 04, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Assignment 4 - Heart rate, respiration and interpersonal coordination

Physiological data (here heart rate [variability], and respiration) are increasingly popular. Historically treated as pernicious noise to be regressed out of neuro-imaging data, there is now increasing research on how these signals tell us something important about cognition and beyond being just a signal of cognitive processes also impact them in interesting ways. Advanced sport science, and the quantified self movement (closely followed by marketing and communication) have hailed continuous physiological tracking as a powerful way to access and modify attitudes, habits, and performance. Further, as team coordination (in the military, in decision processes and organizational contexts) is more and more in focus, research has attempted to measure how interpersonal coordination between physiological systems might tell us something important about e.g. emotional and cognitive coordination. See references in the reading list for more on this.

In this assignment, you will learn to:
- collect physiological data
- pre-process physiological data (and grow further your mad R skills)
- model the continuous interdependence between two signals (using a multilevel model as proxy for a dynamical system approach)
- conservatively assess the presence of coordination between to signals in a controlled context

This assignment has two parts. The first part familiarizes you with heart rate, and respiration data and their preprocessing. The second part explores how to analyze interpersonal coordination of these signals.

These are the questions you need to be able to answer at the end of the assignment (aka that you need to submit as part of the portfolio)

1) How do you preprocess heart rate and respiration data? Describe the process. If any data needs to be excluded, list the excluded data and motivate the exclusion.

2) Do you observe interpersonal coordination in heart rate and respiration? Describe your control baseline, the method used to quantify coordination, and the statistical models used to infer whether coordination was higher than in the baseline. Report the results of the models.

3) Do you observe differences in coordination between conditions? Report the models and results.

4) Is respiration coordination a likely driver of heart rate coordination? Describe how you would test for it. Bonus points if you actually run the tests and report methods and results.

N.B. to give you a bit more data I included data from previous years (Study1, Study2 and Study 3). Note that synchronouns and turn-taking are the same across both studies, but the third condition is different: in the first year it was self-paced joint reading; in the second year it was the tv-series conversation.

## Let's get started

### Exploring physiological signals

- Choose one pair (one pair, three conditions)
- Load the logs
- Produce a plot of the participants' respiration signal and a different one of the participants' HR signal.
  N.B: remember the slides: artifacts, downsampling, scaling.
  N.B. The gridExtra::grid.arrange() function allows you to display the plots side by side. E.g. grid.arrange(plot1, plot2, plot3, ncol=3). There are also smarter packages, like cowplot and ggpubr.
- Can you eye-ball which condition if any displays more physiological coordination?

### First we read one data file and identify the procedure
- Load the file
- correctly identify all columns
- plot the data
- deal with the artifacts
- downsample the dat
- Add a column for study, group, trial and condition

```{r}
# Load the libraries

  library(pacman)
p_load(tidyverse, gridExtra, groupdata2, reshape, lme4)



# Load the file

S2_G10_T1 <- read.csv("data/Study2_G10_T1_Conversation.csv")


# Plot

plot_resp <- ggplot(S2_G10_T1, aes(time))+
  geom_line(aes(y=Resp1, colour = "Resp1"))+
  geom_line(aes(y=Resp2, colour = "Resp2"))+
  ylab("Respiration")+
  ggtitle("Respiration")
plot_resp


plot_hr <- ggplot(S2_G10_T1, aes(time))+
  geom_line(aes(y=HR1, colour = "HR1"))+
  geom_line(aes(y=HR2, colour = "HR2"))+
  ylab("Heart rate")+
  ggtitle("Heart rate")
plot_hr


## Remove outliers

### Tip, check the function below
removeOuts <- function(ts,threshold){
  ts[ts > (mean(ts,na.rm=T) +
             (threshold*sd(ts,na.rm=T))) | 
       ts < (mean(ts,na.rm=T) -
             (threshold*sd(ts,na.rm=T)))] = mean(ts,na.rm=T)
  return(ts)
}
threshold=2.5 # Default value at 2.5 sds from the mean

#Removing outliers
S2_G10_T1$Resp1_clean <- removeOuts(S2_G10_T1$Resp1, threshold)
S2_G10_T1$Resp2_clean <- removeOuts(S2_G10_T1$Resp2, threshold)
S2_G10_T1$HR1_clean <- removeOuts(S2_G10_T1$HR1, threshold)
S2_G10_T1$HR2_clean <- removeOuts(S2_G10_T1$HR2, threshold)

# Plot raw data againt those with the artifacts removed
plot_resp_clean <- ggplot(S2_G10_T1, aes(time))+
  geom_line(aes(y=Resp1_clean, colour = "Resp1"))+
  geom_line(aes(y=Resp2_clean, colour = "Resp2"))+
  ylab("Respiration")+
  ggtitle("Respiration clean")
plot_resp_clean


plot_hr_clean <- ggplot(S2_G10_T1, aes(time))+
  geom_line(aes(y=HR1_clean, colour = "HR1"))+
  geom_line(aes(y=HR2_clean, colour = "HR2"))+
  ylab("Heart rate")+
  ggtitle("Heart rate clean")
plot_hr_clean

all_plots <- grid.arrange(plot_resp, plot_hr, plot_resp_clean, plot_hr_clean, ncol=2)


#Scaling data
S2_G10_T1$Resp1_clean_scale <- scale(S2_G10_T1$Resp1_clean)
S2_G10_T1$Resp2_clean_scale <- scale(S2_G10_T1$Resp2_clean)
S2_G10_T1$HR1_clean_scale <- scale(S2_G10_T1$HR1_clean)
S2_G10_T1$HR2_clean_scale <- scale(S2_G10_T1$HR2_clean)

# Plot again to check how scaled data look like
plot_resp_clean_scale <- ggplot(S2_G10_T1, aes(time))+
  geom_line(aes(y=Resp1_clean_scale, colour = "Resp1"))+
  geom_line(aes(y=Resp2_clean_scale, colour = "Resp2"))+
  ylab("Respiration")+
  ggtitle("Respiration clean scaled")
plot_resp_clean_scale


plot_hr_clean_scale <- ggplot(S2_G10_T1, aes(time))+
  geom_line(aes(y=HR1_clean_scale, colour = "HR1"))+
  geom_line(aes(y=HR2_clean_scale, colour = "HR2"))+
  ylab("Heart rate")+
  ggtitle("Heart rate clean scaled")
plot_hr_clean_scale

all_plots2 <- grid.arrange(plot_resp_clean, plot_hr_clean, plot_resp_clean_scale, plot_hr_clean_scale, ncol=2)

## Downsample in groups n = 100
ds_data <- S2_G10_T1 %>%
  group(n = 100, method = 'greedy') %>%
  dplyr::summarise(
    time = mean(time,na.rm=T),
    HR1 = mean(HR1_clean_scale,na.rm=T),
    HR2 = mean(HR2_clean_scale,na.rm=T),
    Resp1 = mean(Resp1_clean_scale,na.rm=T),
    Resp2 = mean(Resp2_clean_scale,na.rm=T),
    ) 


## Plot the downsampled data
plot_ds_resp <- ggplot(data = ds_data) +
  geom_path(aes(time, Resp1, color = "P1")) +
  geom_path(aes(time, Resp2, color = "P2")) +
  labs(x = "time", y = "Resp") +
  theme(legend.position="bottom")
plot_ds_resp

plot_ds_hr <- ggplot(data = ds_data) +
  geom_path(aes(time, HR1, color = "P1")) +
  geom_path(aes(time, HR2, color = "P2")) +
  labs(x = "time", y = "HR") +
  theme(legend.position="bottom")
plot_ds_hr

## Adding the group, trial, condition to the cleaned up, scaled, downsampled data
ds_data$study <- "S2"
ds_data$group <- "G10"
ds_data$trial <- "T1"
ds_data$condition <- "Conversation"

head(ds_data)

```


## Now we are ready to go to load and pre-process all files

Go through all the files (with a function passed onto map_df), check which files should be excluded, if any, and save the pre-processed time-series

A couple of tips:
- looping is oh so slow. Making a function and using Map/Map_df is your salvation.
- each study restarts the group numbering, so you should make sure to change that (e.g. 100 * Study + Group)
- you need to make sure all the data are meaningful or something has to be removed. Plotting is your friend. E.g. "Study1_G1_T1_Synchronous" has one bad respiration signal. We could replace it with NAs


```{r}
# Define a function running the loading, artifact removal, scaling, downsampling, info adding.

data_preprocess <- function(filename, threshold = 2.5){
  name <- read.csv(filename)
  vari <- c("time", "TimeMs")
  colnames(name)[(colnames(name) %in% vari)] <- "time" 
  name$Resp1 <- scale(removeOuts(name$Resp1, threshold))
  name$Resp2 <- scale(removeOuts(name$Resp2, threshold))
  name$HR1 <- scale(removeOuts(name$HR1, threshold))
  name$HR2 <- scale(removeOuts(name$HR2, threshold))
  name <- name %>%
  group(n = 1000, method = 'greedy') %>% #groups size n = 1000
  dplyr::summarise(
    time = mean(time,na.rm=T),
    HR1 = mean(HR1,na.rm=T),
    HR2 = mean(HR2,na.rm=T),
    Resp1 = mean(Resp1,na.rm=T),
    Resp2 = mean(Resp2,na.rm=T)
    ) 
  name$study <- str_extract(filename, "Study[0-9]{1}")
  name$group <- str_extract(filename, "G[0-9]{1,2}")
  name$trial <- str_extract(filename, "T[1-9]{1}")
  name$condition <- na.omit(str_extract(filename, c("Conversation", "MovementCoop", "MovementGuided", "TurnTaking", "SelfPaced", "Synchronous")))[1]
  name$groupid <- str_extract(filename, "Study[0-9]{1}_G[0-9]{1,2}")
  name$unique <- paste(name$groupid, name$trial, sep = "_")
  return(name)

}


#listing files
files <- list.files(path = "C:/Users/jacda/Desktop/Cognitive science/R-stuff/Class work 3/Assignment_4/data/", pattern = "*.csv", full.names = T) 

#creating data frame
phys_data <- map_df(files, data_preprocess) 



#Some of the data had only NA's in rows so we removed it
phys_data[which(is.na(phys_data$condition) == TRUE),]
phys_data <- phys_data[which(is.na(phys_data$condition) == FALSE),]

#Ensuring time is in the right format
plot(phys_data$time)

#Changing time vairables to seconds
phys_data$time[phys_data$study == "Study3"] <- phys_data$time[phys_data$study == "Study3"]/1000
phys_data$time[phys_data$study == "Study4"] <- phys_data$time[phys_data$study == "Study4"]/1000
phys_data$time[phys_data$study == "Study1"] <- phys_data$time[phys_data$study == "Study1"]*60
phys_data$time[phys_data$study == "Study2"] <- phys_data$time[phys_data$study == "Study2"]*60

#Ensuring time is in the right format
plot(phys_data$time)


#Creating function to check for artifacta.
#The function checks if the standard deviation in a given window of size n is 0 and saves those windows that are in a df. The window moves m steps as specified in the function
rolling_in_the_deep <- function(data, variable, window_l, steps){
  li <- data.frame()
  dat <- data
  l <- as.list(dat[,colnames(dat) == variable])
  for (i in seq(1, nrow(dat), steps)){
  log <- sd(l[[1]][(i):(i+(window_l-1))]) == 0
  li[i,1] <- log
  li[i,2:(2+(window_l-1))] <- c((i):(i+(window_l-1)))
}
  li <- li[is.na(li[,1])==F,]
  li <- li[li[,1]==T,]
  return(li)
}

#applying the function and figuring out which rows are contained in the windows
noarthr1 <- rolling_in_the_deep(phys_data, "HR1", 2, 1)
u_noarthr1 <- unique(c((noarthr1$V2), (noarthr1$V3)))

#They are changed to NA
phys_data$HR1[u_noarthr1] <- NA


noarthr2 <- rolling_in_the_deep(phys_data, "HR2", 2, 1)
u_noarthr2 <- unique(c(unique(noarthr2$V2), unique(noarthr2$V3)))

phys_data$HR2[u_noarthr2] <- NA


noartresp1 <- rolling_in_the_deep(phys_data, "Resp1", 2, 1)
u_noartresp1 <- unique(c(unique(noartresp1$V2), unique(noartresp1$V3)))

phys_data$Resp1[u_noartresp1] <- NA


noartresp2 <- rolling_in_the_deep(phys_data, "Resp2", 2, 1)
u_noartresp2 <- unique(c(unique(noartresp2$V2), unique(noartresp2$V3)))

phys_data$Resp2[u_noartresp2] <- NA


#Checking the data for any leftover artifacts by plotting it
ggplot(data = phys_data)+
  geom_line(aes(x = time, y =Resp1, color = "Participant1"))+
  geom_line(aes(x = time, y =Resp2, color = "Participant2"))+
  ggtitle("test")+
  labs(y = "Respiration")+
  facet_wrap(~groupid)


ggplot(data = phys_data)+
  geom_line(aes(x = time, y =HR1, color = "Participant1"))+
  geom_line(aes(x = time, y =HR2, color = "Participant2"))+
  ggtitle("test")+
  labs(y = "Heart rate")+
  facet_wrap(~groupid)


#Creating a column with unique group/trial id
phys_data$unique <- paste(phys_data$groupid, phys_data$trial, sep = "_")

#Re-running the remove outlier function for very influential outliers
phys_data$HR1[phys_data$unique == "Study3_G10_T1"] <- removeOuts(phys_data$HR1[phys_data$unique == "Study3_G10_T1"], threshold = 2.5)

#Re-running the remove outlier function for very influential outliers
phys_data$HR1[phys_data$unique == "Study3_G9_T3"] <- removeOuts(phys_data$HR1[phys_data$unique == "Study3_G9_T3"], threshold = 2.5)


#Signals containing bad data (almost non-existing) we're changed to NAs
phys_data$Resp2[phys_data$groupid == "Study1_G1"] <- NA
phys_data$Resp1[phys_data$groupid == "Study1_G1"] <- NA

phys_data$Resp1[phys_data$unique == "Study1_G2_T1" | phys_data$unique == "Study1_G2_T2"] <- NA
phys_data$Resp2[phys_data$unique == "Study1_G2_T1" | phys_data$unique == "Study1_G2_T2"] <- NA


```

## Now we need to run some analysis

Let's start with a multilevel model that accounts for 
- stability (how each signal is autocorrelated)
- interpersonal dependence (each signal is dependent from the previous state of the other signal)

The data needs to be further prepared, so we can analyze both participants in the same model.
We need to turn the data into a long format:
- a column indicating own hr and one own respiration
- a column indicating other hr and one other respiration
- a column indicating change in hr from previous round and one in respiration

We can then run an analysis where change is a function of one's previous state (stability, see slides), and the other's previous state (coupling). Make sure to:
- set up the most interesting contrasts: how do these parameters vary by condition? which condition should be baseline?
- set up the right random effects.
- N.B. the model will be slow. Make sure it works on a subset of the data first!

Bonus question: what if we include an additional layer? Is my heart rate just adjusting to yours, or also to how much you are adjusting to mine?
- to start answering this we can add a column indicating the previous change in hr in the other and one in respiration
- we can then build on the previous models by also adding the previous change in the other


```{r}

# Genearate a column for each: previous HR1, HR2, Resp1, Resp2

phys_data$HR1_prev <- lag(phys_data$HR1,1)
phys_data$HR2_prev <- lag(phys_data$HR2,1)
phys_data$Resp1_prev <- lag(phys_data$Resp1,1)
phys_data$Resp2_prev <- lag(phys_data$Resp2,1)

# Genearate a column for each: change in HR1, HR2, Resp1, Resp2

phys_data$HR1_change <- phys_data$HR1-phys_data$HR1_prev
phys_data$HR2_change <- phys_data$HR2-phys_data$HR2_prev
phys_data$Resp1_change <- phys_data$Resp1-phys_data$Resp1_prev
phys_data$Resp2_change <- phys_data$Resp2-phys_data$Resp2_prev

# Make the data long, so we can analyze both participants at the same time 

phys_data_long <-melt(phys_data, id.vars = c("study", "time", "groupid", "unique", "condition" ), measure.vars = c("HR1_prev", "Resp1_prev"))

phys_data_long[,8:9] <-melt(phys_data, id.vars = c("study", "time", "groupid", "unique", "condition" ), measure.vars = c("HR2_prev", "Resp2_prev"))[6:7]

phys_data_long[,10:11] <-melt(phys_data, id.vars = c("study", "time", "groupid", "unique", "condition" ), measure.vars = c("HR1_change", "Resp1_change"))[6:7]

names(phys_data_long) <- c(colnames(phys_data_long)[1:5], "Self", "Self_data", "Other", "Other_data", "Change", "Change_data")



#Creating a simpe model looking at the effect of the other's previous state and one's own previous state

model0 <- lmer(Change_data ~ 0 + (Other_data + Self_data) + (0+condition|groupid), phys_data_long, REML = F,  control = lmerControl(
  optimizer = "nloptwrap",
  calc.derivs = F,
  optCtrl = list(
    ftol_abs = 1e-10,
    xtol_abs = 1e-10,
    maxeval = 100000
  )))

#summary of model
summary(model0)

#summary of model with lmerTest for p-values
summary(lmerTest::as_lmerModLmerTest(model0))

#Creating model as before but including the main effect of condition and the effect of the interaction between condition and the other's previous state and one's own previous state
model1 <- lmer(Change_data ~ 0 + condition + (Other_data + Self_data):condition + (0+condition|groupid), phys_data_long, REML = F,  control = lmerControl(
  optimizer = "nloptwrap",
  calc.derivs = F,
  optCtrl = list(
    ftol_abs = 1e-10,
    xtol_abs = 1e-10,
    maxeval = 100000
  )))

#summary of model
summary(model1)

#summary of model with lmerTest for p-values
model1_test <- lmerTest::as_lmerModLmerTest(model1)
summary(model1_test)


```


## Now we need to create control baselines.

First shuffled controls, then surrogate pairs.

### Creating controls: shuffled controls

Shuffled controls break the temporal dependencies of time-series by shuffling the value within one time-series. This ensures the "coordination" observed is not due to the actual values in the series and not their sequence.
Tip: sample() is your friend, but make sure to shuffle things within participant/condition and not throughout the whole dataset
 
```{r}

#Since we will be working with the sample() function we set a seed for replication purposes
set.seed(1)

#creating a function for shuffling varibales by group
everyday_Im_shuffling <- function(group, variable){
  variable_shuf <- c()
  shuf <- by(variable, group, sample)
  for (i in 1:length(shuf)){
  variable_shuf[names(shuf)[i]==group] <- shuf[[i]]
  }
  return(variable_shuf)
}


# Genearate a column for each: shuffled HR1, HR2, Resp1, Resp2, grouping by participant/condition
phys_data$HR1_shuf <- everyday_Im_shuffling(phys_data$unique, phys_data$HR1)
phys_data$HR2_shuf <- everyday_Im_shuffling(phys_data$unique, phys_data$HR2)
phys_data$Resp1_shuf <- everyday_Im_shuffling(phys_data$unique, phys_data$Resp1)
phys_data$Resp2_shuf <- everyday_Im_shuffling(phys_data$unique, phys_data$Resp2)

# Genearate a column for each: previous shuffled HR1, HR2, Resp1, Resp2
phys_data$HR1_shuf_prev <- lag(phys_data$HR1_shuf,1)
phys_data$HR2_shuf_prev <- lag(phys_data$HR2_shuf,1)
phys_data$Resp1_shuf_prev <- lag(phys_data$Resp1_shuf,1)
phys_data$Resp2_shuf_prev <- lag(phys_data$Resp2_shuf,1)

# Genearate a column for each: shuffled change in HR1, HR2, Resp1, Resp2

phys_data$HR1_shuf_change <- phys_data$HR1_shuf-phys_data$HR1_shuf_prev
phys_data$HR2_shuf_change <- phys_data$HR2_shuf-phys_data$HR2_shuf_prev
phys_data$Resp1_shuf_change <- phys_data$Resp1_shuf-phys_data$Resp1_shuf_prev
phys_data$Resp2_shuf_change <- phys_data$Resp2_shuf-phys_data$Resp2_shuf_prev

# Make the data long, so we can analyze both participants at the same time 

phys_data_long_shuf <-melt(phys_data, id.vars = c("study", "time", "groupid", "unique", "condition" ), measure.vars = c("HR1_shuf_prev", "Resp1_shuf_prev"))

phys_data_long_shuf[,8:9] <-melt(phys_data, id.vars = c("study", "time", "groupid", "unique", "condition" ), measure.vars = c("HR2_shuf_prev", "Resp2_shuf_prev"))[6:7]

phys_data_long_shuf[,10:11] <-melt(phys_data, id.vars = c("study", "time", "groupid", "unique", "condition" ), measure.vars = c("HR1_shuf_change", "Resp1_shuf_change"))[6:7]

names(phys_data_long_shuf) <- c(colnames(phys_data_long_shuf)[1:5], "Self", "Self_data", "Other", "Other_data", "Change", "Change_data")



#Binding shuffled dataset with the unshuffled dataset
phys_data_long_alt <- bind_rows(phys_data_long, phys_data_long_shuf)

#Creating column specifying wether the data is from the shuffled or unshuffled dataset
phys_data_long_alt$real_v_shuf <- ifelse(phys_data_long_alt$Self == c("HR1_prev","Resp1_prev"), "real", "shuf")



# Create the same model as in the previous chunk, but adding an interaction by shuffled vs. real
model_shuf <- lmer(Change_data ~ 0 + (condition + (Other_data + Self_data):condition):real_v_shuf + (0+condition|groupid), phys_data_long_alt, REML = F,  control = lmerControl(
  optimizer = "nloptwrap",
  calc.derivs = F,
  optCtrl = list(
    ftol_abs = 1e-10,
    xtol_abs = 1e-10,
    maxeval = 10000
  )))

#summary of model
summary(model_shuf)

#summary of model using lmerTest for p-values
model_shuf_test <- lmerTest::as_lmerModLmerTest(model_shuf)
summary(model_shuf_test)

```
 
 
### TRICKY! Creating controls: surrogate pair controls
 - Per each real pair, identify at least one surrogate pair (matching one of the participants, with somebody doing the same task, but in a different pair)

```{r}

# Identify unique pairs within a given study (to keep things manageable) and create list of possible surrogate pairs (e.g. individual 1 from pair 1 and individual 2 from pair 2)

#Looping through the studies independently and writing to new df
#Using wide phys_data after all preprocessing + addition of lag + change columns

phys_data_clean <- phys_data
colnames(phys_data_clean)[8] <- "Study"
colnames(phys_data_clean)[11] <- "Condition"
colnames(phys_data_clean)[9] <- "Group"
colnames(phys_data_clean)[12] <- "GroupID"

#Study 1
Groups<-unique(phys_data_clean$Group[phys_data_clean$Study=="Study1"])
SurrogateList<-expand.grid(a=Groups,b=Groups)
SurrogateList=subset(SurrogateList,a!=b)

data_1<-subset(phys_data_clean,Study=="Study1")
surrogate_data1<-data_1[0,]

for (i in 1:nrow(SurrogateList)){
  x<-subset(data_1,Group==SurrogateList$a[i])
  y<-subset(data_1,Group==SurrogateList$b[i])
  newpairID<-c(800+((1:4)*i))
  for (co in c("Synchronous","TurnTaking","SelfPaced","Conversation","MovementGuided","MovementCoop")){
    if (co %in% unique(x$Condition) & co %in% unique(y$Condition)){
      z1<-subset(x,Condition==co)
      z2<-subset(y,Condition==co)
      if (nrow(z1)>nrow(z2)){
        z1<-z1[1:nrow(z2),]
      }
      if (nrow(z2)>nrow(z1)){
        z2<-z2[1:nrow(z1),]
      }
      w1<-z1 %>% mutate(
        HR2=z2$HR2,
        Resp2=z2$Resp2,
        HR2_prev=z2$HR2_prev,
        Resp2_prev=z2$Resp2_prev,
        HR2_change=z2$HR2_change,
        Resp2_change=z2$Resp2_change)
            if (nrow(surrogate_data1) == 0) {
        surrogate_data1 <- w1
        }
        else {
          surrogate_data1 <- rbind(surrogate_data1,w1)
  }}}
}

#Study 2
Groups<-unique(phys_data_clean$Group[phys_data_clean$Study=="Study2"])
SurrogateList<-expand.grid(a=Groups,b=Groups)
SurrogateList=subset(SurrogateList,a!=b)

data_2<-subset(phys_data_clean,Study=="Study2")
surrogate_data2<-data_2[0,]

for (i in 1:nrow(SurrogateList)){
  x<-subset(data_2,Group==SurrogateList$a[i])
  y<-subset(data_2,Group==SurrogateList$b[i])
  newpairID<-c(800+((1:4)*i))
  for (co in c("Synchronous","TurnTaking","SelfPaced","Conversation","MovementGuided","MovementCoop")){
    if (co %in% unique(x$Condition) & co %in% unique(y$Condition)){
      z1<-subset(x,Condition==co)
      z2<-subset(y,Condition==co)
      if (nrow(z1)>nrow(z2)){
        z1<-z1[1:nrow(z2),]
      }
      if (nrow(z2)>nrow(z1)){
        z2<-z2[1:nrow(z1),]
      }
      w1<-z1 %>% mutate(
        HR2=z2$HR2,
        Resp2=z2$Resp2,
        HR2_prev=z2$HR2_prev,
        Resp2_prev=z2$Resp2_prev,
        HR2_change=z2$HR2_change,
        Resp2_change=z2$Resp2_change)
            if (nrow(surrogate_data2) == 0) {
        surrogate_data2 <- w1
        }
        else {
          surrogate_data2 <- rbind(surrogate_data2,w1)
  }}}
}

#Study 3
Groups<-unique(phys_data_clean$Group[phys_data_clean$Study=="Study3"])
SurrogateList<-expand.grid(a=Groups,b=Groups)
SurrogateList=subset(SurrogateList,a!=b)

data_3<-subset(phys_data_clean,Study=="Study3")
surrogate_data3<-data_3[0,]

for (i in 1:nrow(SurrogateList)){
  x<-subset(data_3,Group==SurrogateList$a[i])
  y<-subset(data_3,Group==SurrogateList$b[i])
  newpairID<-c(800+((1:4)*i))
  for (co in c("Synchronous","TurnTaking","SelfPaced","Conversation","MovementGuided","MovementCoop")){
    if (co %in% unique(x$Condition) & co %in% unique(y$Condition)){
      z1<-subset(x,Condition==co)
      z2<-subset(y,Condition==co)
      if (nrow(z1)>nrow(z2)){
        z1<-z1[1:nrow(z2),]
      }
      if (nrow(z2)>nrow(z1)){
        z2<-z2[1:nrow(z1),]
      }
      w1<-z1 %>% mutate(
        HR2=z2$HR2,
        Resp2=z2$Resp2,
        HR2_prev=z2$HR2_prev,
        Resp2_prev=z2$Resp2_prev,
        HR2_change=z2$HR2_change,
        Resp2_change=z2$Resp2_change)
            if (nrow(surrogate_data3) == 0) {
        surrogate_data3 <- w1
        }
        else {
          surrogate_data3 <- rbind(surrogate_data3,w1)
  }}}
}

#Study 4
Groups<-unique(phys_data_clean$Group[phys_data_clean$Study=="Study4"])
SurrogateList<-expand.grid(a=Groups,b=Groups)
SurrogateList=subset(SurrogateList,a!=b)

data_4<-subset(phys_data_clean,Study=="Study4")
surrogate_data4<-data_4[0,]

for (i in 1:nrow(SurrogateList)){
  x<-subset(data_4,Group==SurrogateList$a[i])
  y<-subset(data_4,Group==SurrogateList$b[i])
  newpairID<-c(800+((1:4)*i))
  for (co in c("Synchronous","TurnTaking","SelfPaced","Conversation","MovementGuided","MovementCoop")){
    if (co %in% unique(x$Condition) & co %in% unique(y$Condition)){
      z1<-subset(x,Condition==co)
      z2<-subset(y,Condition==co)
      if (nrow(z1)>nrow(z2)){
        z1<-z1[1:nrow(z2),]
      }
      if (nrow(z2)>nrow(z1)){
        z2<-z2[1:nrow(z1),]
      }
      w1<-z1 %>% mutate(
        HR2=z2$HR2,
        Resp2=z2$Resp2,
        HR2_prev=z2$HR2_prev,
        Resp2_prev=z2$Resp2_prev,
        HR2_change=z2$HR2_change,
        Resp2_change=z2$Resp2_change)
            if (nrow(surrogate_data4) == 0) {
        surrogate_data4 <- w1
        }
        else {
          surrogate_data4 <- rbind(surrogate_data4,w1)
  }}}
}


#Binding all surrogate dfs to a full df with all surrogate pairs
all_surr<-rbind(surrogate_data1,surrogate_data2,surrogate_data3,surrogate_data4)

#Transforming to long format (equal to method for phys_data_long)
all_surr<-all_surr %>% select(c(time,HR1,HR2,Resp1,Resp2,Study,Condition,GroupID,unique,HR1_prev,Resp1_prev,HR2_prev,Resp2_prev,HR1_change,Resp1_change))

all_surr_2<-reshape2::melt(all_surr, id.vars = c("time","Study","Condition","GroupID","unique"), measure.vars = c("HR1_prev","Resp1_prev"))
names(all_surr_2)<-c("Time","Study","Condition","GroupID","Unique","own_prev","own_prev_value")

all_surr_3<-reshape2::melt(all_surr, id.vars = c("time","Study","Condition","GroupID","unique"), measure.vars = c("HR1_change","Resp1_change"))        
names(all_surr_3)<-c("Time","Study","Condition","GroupID","Unique","own_change","own_change_value")
all_surr_3<-all_surr_3 %>% select(c("own_change","own_change_value"))

all_surr_4<-reshape2::melt(all_surr, id.vars = c("time","Study","Condition","GroupID","unique"), measure.vars = c("HR2_prev","Resp2_prev")) 
names(all_surr_4)<-c("Time","Study","Condition","GroupID","Unique","other_prev","other_prev_value")
all_surr_4<-all_surr_4 %>% select(c("other_prev","other_prev_value"))

#Binding stacked dfs
all_surr_long<-cbind(all_surr_2,all_surr_3,all_surr_4)

#Adding a type column in original and surrogate data 
phys_data_long$Type<-"Real"
all_surr_long$Type<-"Surrogate"

#Binding original and surrogate data 
all_surr_long <- all_surr_long[,c(2,1,4,5,3,6:12)]
colnames(all_surr_long) <- colnames(phys_data_long)
all_data<-rbind(phys_data_long,all_surr_long)




# Create models as in chunks above, but adding an interaction with the Real vs. Surrogate variable (exclude shuffled ones for simplicity)
model_surr <- lmer(Change_data ~ 0 + (condition + (Other_data + Self_data):condition):Type + (0+condition|groupid), all_data, REML = F,  control = lmerControl(
  optimizer = "nloptwrap",
  calc.derivs = F,
  optCtrl = list(
    ftol_abs = 1e-10,
    xtol_abs = 1e-10,
    maxeval = 10000
  )))

#summary of model
summary(model_surr)

#summary of model using lmerTest for p-values
model_surr_test <- lmerTest::as_lmerModLmerTest(model_surr)
summary(model_surr_test)

```
 

 